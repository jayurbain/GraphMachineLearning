{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent\n",
    "\n",
    "Jay Urbain\n",
    "12/10/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) is an optimization algorithm used to find the local minimum of a function. It is commonly used in many different machine learning algorithms. \n",
    "\n",
    "Complete the code for the following functions below:   \n",
    "- dLdw1() # partial derivative of the loss (cost) with respect to w1\n",
    "- dLdw0() # partial derivative of the loss (cost) with respect to w0\n",
    "- f() # linear regression prediction function\n",
    "- cost() # cost function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading necessary libraries and setting up plotting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate plots within notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset into a Pandas dataframe\n",
    "# You'll need to change the 'f' path\n",
    "f = \"ex1data1.txt\"\n",
    "df = pd.read_csv(f, header=None, names=[\"X\",\"Y\"])\n",
    "\n",
    "# verify\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# Convert pandas columns for X, Y into numpy arrays for processing\n",
    "X=df.iloc[:,0].values\n",
    "Y=df.iloc[:,1].values\n",
    "\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "print(X.shape[0])\n",
    "print(X[:5])\n",
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default settings, you need to determine optimal convergence settings\n",
    "alpha = 0.01;    # learning rate\n",
    "tol = 1e-11;     # tolerance to determine convergence\n",
    "maxiter = 1000;  # maximum number of iterations (in case convergence is not reached)\n",
    "dispiter = 10;   # interval for displaying results during iterations\n",
    "\n",
    "# track interations\n",
    "iters = 0;\n",
    "# parameter initialization\n",
    "w0 = -0.01;\n",
    "w1 = 00.01;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track results for plotting parameter convergence\n",
    "w0plot = [0.0]*(maxiter+1);\n",
    "w1plot = [0.0]*(maxiter+1);\n",
    "tplot  = [0]*(maxiter+1);\n",
    "cplot  = [0]*(maxiter+1);\n",
    "\n",
    "w0plot[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a scatter plot with labels and title to visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate _nice_ initial scatter plot with labels to visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels\n",
    "# Create a Figure object.\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "# Create an Axes object.\n",
    "ax = fig.add_subplot(1,1,1) # one row, one column, first plot\n",
    "# Plot the data.\n",
    "ax.scatter(X, Y, color=\"red\", marker=\"*\")\n",
    "# Add a title.\n",
    "ax.set_title(\"Data set\")\n",
    "# Add axis labels.\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "# Produce an image.\n",
    "#fig.savefig(\"scatterplot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions you need to complete !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression predictive function\n",
    "def f(x):\n",
    "    ##################### \n",
    "    # fill this in\n",
    "    return w0 + w1*x\n",
    "    #####################\n",
    "    \n",
    "# partial derivative of the cost(loss) with respect to w1 (slope)\n",
    "def dLdw1():\n",
    "    ##################### \n",
    "    # fill this in\n",
    "    return -2/X.size * np.sum( (Y-f(X))*X )\n",
    "    #####################\n",
    "    \n",
    "# partial derivative of the cost(loss) with respect to w0 (bias)\n",
    "def dLdw0():\n",
    "    ##################### \n",
    "    # fill this in\n",
    "    return -2/X.size * np.sum( (Y-f(X)) )\n",
    "    #####################\n",
    "    \n",
    "def cost():\n",
    "    ##################### \n",
    "    # fill this in\n",
    "    return np.sum( (Y-f(X))**2 ) / X.size\n",
    "    #####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main loop of program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main algorithm loop starts here\n",
    "iters = 0\n",
    "maxiters = 10\n",
    "while True:\n",
    "    # Note: need to implement dLdw1 and dLdw0 (above)\n",
    "    delta1 = alpha * dLdw1()\n",
    "    delta0 = alpha * dLdw0()\n",
    "\n",
    "    # Store data for plotting convergence of parameters\n",
    "    tplot[iters] = iters\n",
    "    w0plot[iters] = w0\n",
    "    w1plot[iters] = w1\n",
    "    cplot[iters] = cost()\n",
    " \n",
    "    iters+=1\n",
    "    w1 = w1 - delta1\n",
    "    w0 = w0 - delta0\n",
    " \n",
    "    # display progress\n",
    "    if iters % dispiter == 0:\n",
    "        print(str(iters), \", w0=\", str(w0), \" delta0=\", str(delta0), \"w1=\", str(w1), \", delta1=\", str(delta1))\n",
    "\n",
    "    if abs(delta1) <= tol or abs(delta0) <= tol or iters > maxiter:\n",
    "        break\n",
    "\n",
    "print(\"\\nConvergence after \" + str(iters) + \" iterations: w0=\" + str(w0) + \", w1=\" + str(w1));\n",
    "\n",
    "print(cplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate scatter plot with linear regression fit line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels\n",
    "# Create a Figure object.\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "# Create an Axes object.\n",
    "ax = fig.add_subplot(1,1,1) # one row, one column, first plot\n",
    "# Plot the data.\n",
    "ax.scatter(X, Y, color=\"blue\")\n",
    "# Add a title.\n",
    "ax.set_title(\"Data set with linear regression fit\")\n",
    "# Add axis labels.\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "# Produce an image.\n",
    "#fig.savefig(\"scatterplot.png\")\n",
    "ax.plot(X, w0+w1*X, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot convergence of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels\n",
    "# Create a Figure object.\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "# Create an Axes object.\n",
    "ax = fig.add_subplot(1,1,1) # one row, one column, first plot\n",
    "# Plot the data.    \n",
    "ax.plot(tplot, w0plot, color=\"blue\", label=\"w0\")\n",
    "ax.plot(tplot, w1plot, color=\"red\", label=\"w1\")\n",
    "# Add a title.\n",
    "ax.set_title(\"Convergence of w0 and w1\")\n",
    "# Add axis labels.\n",
    "ax.set_xlabel(\"Iterations\")\n",
    "ax.set_ylabel(\"Parameters\")\n",
    "ax.legend(loc='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot convergence of cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels\n",
    "# Create a Figure object.\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "# Create an Axes object.\n",
    "ax = fig.add_subplot(1,1,1) # one row, one column, first plot\n",
    "# Plot the data.    \n",
    "ax.plot(tplot, cplot, color=\"blue\", label=\"Cost\")\n",
    "# Add a title.\n",
    "ax.set_title(\"Cost function trend\")\n",
    "# Add axis labels.\n",
    "ax.set_xlabel(\"Iterations\")\n",
    "ax.set_ylabel(\"Cost\")\n",
    "ax.legend(loc='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the parameters and the cost function converge at different rates. We could also try terminating our gradient descent algorithm based on the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "pytorch_quant",
   "language": "python",
   "name": "pytorch_quant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
