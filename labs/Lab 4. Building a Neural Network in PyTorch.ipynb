{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b0883b",
   "metadata": {},
   "source": [
    "## Lab 4. Building a Neural Network in PyTorch\n",
    "\n",
    "Jay Urbain, PhD\n",
    "\n",
    "12/30/2022, 1/4/2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c734e02",
   "metadata": {},
   "source": [
    "Lab 4: In This assignment we will be building nueral networks in PyTorch to classify images in the `FashionMNIST` dataset. \n",
    "\n",
    "The assignments consiste of three parts. Part 1 is actually done for you and is meant as a tutorial. Make sure you read and execute the notebook. In part 2, you will create a basic convolutional neural network as described below. In part 3, you are encouraged to improve the performance of the network. Do a little thinking and research. Good luck!\n",
    "\n",
    "TODO: Part 1: Create a neural network model   \n",
    "TODO: Part 2: Create a convolutional neural network model   \n",
    "TODO: Part 3: Improve your convolutional neural network model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defce639",
   "metadata": {},
   "source": [
    "PyTorch offers domain-specific libraries such as `TorchText`, `TorchVision`, and `TorchAudio`, all of which include datasets. \n",
    "\n",
    "We will be using the `FashionMNIST` dataset from `1TorchVision`. \n",
    "\n",
    "https://www.kaggle.com/code/pavansanagapati/a-simple-cnn-model-beginner-guide/data\n",
    "\n",
    "Code for processing data samples can get messy and hard to maintain. We  want our dataset code to be decoupled from our model training code for better readability and modularity. \n",
    "\n",
    "PyTorch provides two data primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "If you have a custom data set you'll need to create an instance of `torch.utils.data.Dataset` for your files.\n",
    "\n",
    "Note: We're only performing one basic transformation, `ToTensor` to transform are numpy ndarray's into a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c12395",
   "metadata": {},
   "source": [
    "Examine the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_ = training_data[0][0].numpy().reshape(28, 28)\n",
    "plt.imshow(img_, cmap='gray')\n",
    "plt.show()\n",
    "img_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fac59d",
   "metadata": {},
   "source": [
    "Pass the Dataset as an argument to `DataLoader`. This wraps an iterable over the dataset, and supports automatic batching, sampling, shuffling and multiprocess data loading. Another benefit is the ability to perform data manipulation. But don't over do it since you want data loading to be efficient.\n",
    "\n",
    "Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71664b3e",
   "metadata": {},
   "source": [
    "#### Creating Models\n",
    "\n",
    "To define a neural network in PyTorch, create a class that inherits from nn.Module. \n",
    "\n",
    "Define the layers of the network in the `__init__` function and specify how data will pass through the network in the `forward` function. To accelerate operations in the neural network, move it to the GPU if available.\n",
    "\n",
    "## TODO: Part 1: Create a neural network model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627df9aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06aa1df",
   "metadata": {},
   "source": [
    "## TODO: Part 2: Create a convolutional neural network model \n",
    "\n",
    "First review, the following references:\n",
    "\n",
    "Conv2d  \n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "\n",
    "BatchNorm2d  \n",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html\n",
    "\n",
    "ReLU  \n",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html \n",
    "\n",
    "MaxPool2d  \n",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
    "\n",
    "Linear  \n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html   \n",
    "\n",
    "Second, complete the following ConvNet class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f3120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "\n",
    "class ConvNet(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Defining a 2D 3x3 convolution layer using Conv2d. Use a stride of 1 and padding of 1.\n",
    "            # input channels should be 1, output channels should be 4.\n",
    "\n",
    "            \n",
    "            # Perform batch normilation\n",
    "\n",
    "            \n",
    "            # Apply the ReLU non-linear activation function\n",
    "\n",
    "            \n",
    "            # Reduce the spatial dimensionality by using max pooling with size of 2 and stride of 2.\n",
    "\n",
    "            \n",
    "            # Define another 2D convolution layer\n",
    "            # Be careful to define the correct number of input channels into your convolution layer\n",
    "\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(4 * 7 * 7, 10)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n",
    "    \n",
    "# model = ConvNet().to(device)\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955394f6",
   "metadata": {},
   "source": [
    "## TODO: Part 3: Improve your convolutional neural network model \n",
    "\n",
    "Can you improve the performance of this convolutional neural network and right trash talk your Professor?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2059d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your super duper convnet here\n",
    "\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d607e68f",
   "metadata": {},
   "source": [
    "#### Optimizing the Model Parameters\n",
    "\n",
    "To train a model, define a loss function and an optimizer. Note: We are just using cross entropy loss and stochastic gradient descent as discussed in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3ae58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() # define loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # define optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301147a8",
   "metadata": {},
   "source": [
    "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X) # use model to make a prediction\n",
    "        loss = loss_fn(pred, y) # measure loss with respect to ground truth y\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad() # zero out gradients from last pass\n",
    "        loss.backward() # calculate gradients using cross-entropy\n",
    "        optimizer.step() # optimize model parameters\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f4b39",
   "metadata": {},
   "source": [
    "Define a test function to test the model’s performance against the test dataset to ensure it is learning. This is typically called validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc20150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c3cb3",
   "metadata": {},
   "source": [
    "The training process is conducted over several iterations (epochs). \n",
    "\n",
    "During each epoch, the model learns parameters to make better predictions. \n",
    "\n",
    "Print the model’s accuracy and loss at each epoch. You want to see the accuracy increase and the loss decrease with every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e55532",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5 # you may want to increase this number\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    accuracy, loss = test(test_dataloader, model, loss_fn)\n",
    "    acc_list.append(accuracy)\n",
    "    loss_list.append(loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fded8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"no. of epochs\")\n",
    "plt.ylabel(\"total loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3912a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc_list)\n",
    "plt.xlabel(\"no. of epochs\")\n",
    "plt.ylabel(\"total accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1f320",
   "metadata": {},
   "source": [
    "#### Saving Models\n",
    "\n",
    "You'll want to save your models so you don't have to retrain each time!\n",
    "\n",
    "A common way to save a model is to serialize the internal state dictionary (containing the model parameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32312b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b27aa0",
   "metadata": {},
   "source": [
    "#### Loading Models\n",
    "\n",
    "The process for loading a model includes re-creating the model structure and loading the state dictionary into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "# model = ConvNet()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863f91ef",
   "metadata": {},
   "source": [
    "#### Make predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f6b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "print(x.shape)\n",
    "\n",
    "# approach 1, convert example to torch tensor\n",
    "# Allows you to pick any specific example\n",
    "x = np.expand_dims(x, axis=0)\n",
    "y = np.expand_dims(y, axis=0)\n",
    "x = x.astype(np.float32)\n",
    "y = y.astype(np.int64)\n",
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)\n",
    "\n",
    "# approach 2, use dataloader iterator. \n",
    "# Doesn't allow you to pick a specific example\n",
    "# inputs, classes = next(iter(test_dataloader)) \n",
    "\n",
    "# approach 3, use dataloader \n",
    "# Doesn't allow you to pick a specific example\n",
    "# for X, y in dataloader:\n",
    "#     X, y = X.to(device), y.to(device)\n",
    "#     break\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a047a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_ = test_data[0][0].numpy().reshape(28, 28)\n",
    "plt.imshow(img_, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1248f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_quant",
   "language": "python",
   "name": "pytorch_quant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
